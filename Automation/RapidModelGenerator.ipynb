{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author : Joseph Hencil Peter\n",
    "### (Temasek Admission Id : 1880282G)\n",
    "### Program/Code : RapidModelGenerator\n",
    "\n",
    "#### Description: Auto generate the models in python language based on the minimum input given in the input text file. Each file will have code to record the accuracy, loss and execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import the required libraries\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, Activation\n",
    "from keras.layers import Dense, Softmax\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables (including hyper-parameters)\n",
    "epochs=''\n",
    "batch_size=''\n",
    "layers = ''\n",
    "num_classes ='10'\n",
    "outFileName = ''\n",
    "OptimizerUsed =''\n",
    "Augmentation = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampleOut_2018-12-03_23-22-30.624946\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "/content/gdrive/My Drive/CNNProject/SampleOut_2018-12-03_23-22-30.624946/\n"
     ]
    }
   ],
   "source": [
    "#read the models' input\n",
    "modelInputFileName = 'InputModel.mi'\n",
    "\n",
    "\n",
    "fileStat = os.stat(modelInputFileName)\n",
    "if(fileStat.st_size == 0):\n",
    "    print(\"Model Input file is empty or doesn't exist. Please check...\")\n",
    "    assert(False)\n",
    "\n",
    "#output folder\n",
    "outFolder = 'SampleOut_' + str(dt.datetime.now()) \n",
    "outFolder = outFolder.replace(':','-') \n",
    "outFolder = outFolder.replace(' ','_')\n",
    "formattedOutFolder = '.\\\\' + outFolder + '\\\\'\n",
    "googleBaseFolder = '/content/gdrive/My Drive/CNNProject/' + outFolder + '/'\n",
    "print(outFolder)\n",
    "print(formattedOutFolder)\n",
    "print(googleBaseFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImportSection():\n",
    "    importSection=\"import keras\\nfrom keras import callbacks\\nfrom keras.datasets import cifar10\\nfrom keras.models import Sequential\\n\"\n",
    "    \n",
    "    importSection += \"from keras.layers import Dense, Activation, Softmax, Dropout\\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\\n\"\n",
    "    importSection += \"from keras.optimizers import SGD, RMSprop\\nfrom keras import backend as K\\n\"\n",
    "\n",
    "    importSection += \"import numpy as np\"\n",
    "    importSection += \"\\nfrom datetime import datetime as dt\" \n",
    "    importSection += \"\\nfrom keras.preprocessing.image import ImageDataGenerator\"\n",
    "\n",
    "    #import numpy as np\\\n",
    "    #import matplotlib.pyplot as plt\\\n",
    "    #%matplotlib inline\\\n",
    "    #%config InlineBackend.figure_format='retina'\\\n",
    "    #plt.style.use(\\'ggplot\\')'\n",
    "\n",
    "    return importSection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataLoadAndPreprocessingSection():\n",
    "    dataLoadAndPreProcess = ''\n",
    "    dataLoadAndPreProcess +=\"\\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\"\n",
    "    dataLoadAndPreProcess +=\"\\nimg_rows, img_cols = 32, 32\"\n",
    "    dataLoadAndPreProcess +=\"\\nx_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\"\n",
    "    dataLoadAndPreProcess +=\"\\nx_test = x_test.reshape(x_test.shape[0],  img_rows, img_cols, 3)\"\n",
    "    dataLoadAndPreProcess +=\"\\nx_train = x_train.astype('float32')\"\n",
    "    dataLoadAndPreProcess +=\"\\nx_test = x_test.astype('float32')\"\n",
    "    dataLoadAndPreProcess +=\"\\nx_train /= 255\"\n",
    "    dataLoadAndPreProcess +=\"\\nx_test /= 255\"\n",
    "    dataLoadAndPreProcess +=\"\\ny_train = keras.utils.to_categorical(y_train, num_classes)\"\n",
    "    dataLoadAndPreProcess +=\"\\ny_test = keras.utils.to_categorical(y_test, num_classes)\"\n",
    "    \n",
    "    return dataLoadAndPreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrainingSection():\n",
    "   \n",
    "    trainingSection = 'model.compile(loss=keras.losses.categorical_crossentropy,optimizer=' + OptimizerUsed + ',metrics=[\\'accuracy\\'])'\n",
    "    \n",
    "    #trainingSection += '\\nmodel_checkpoints = callbacks.ModelCheckpoint(\\'' + outFolder + '\\\\' + outFileName + '_weights_{epoch:02d}_{val_loss:.2f}_Proj.h5\\', monitor=\\'val_loss\\','\n",
    "    trainingSection += '\\nmodel_checkpoints = callbacks.ModelCheckpoint(\\'' + googleBaseFolder  + outFileName + '_weights_{epoch:02d}_{val_loss:.2f}_Proj.h5\\', monitor=\\'val_loss\\','\n",
    "    \n",
    "    trainingSection += 'verbose=1, save_best_only=True, save_weights_only=False, mode=\\'auto\\', period=1)'\n",
    "    \n",
    "    if (Augmentation == 'True'):\n",
    "        trainingSection += '\\n\\n#Data Augmentation Enabled'\n",
    "        trainingSection += '\\ndatagen = ImageDataGenerator( rotation_range=90, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)' \n",
    "        trainingSection += '\\ndatagen.fit(x_train)'\n",
    "        trainingSection += '\\nmodel.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,steps_per_epoch=32,'\n",
    "        trainingSection += '\\nvalidation_data=(x_test, y_test),'\n",
    "        trainingSection += '\\nworkers=4)'\n",
    "    else:\n",
    "        trainingSection += '\\n\\n#Training'\n",
    "        trainingSection += '\\nmodel_log = model.fit(x_train, y_train,'\n",
    "        trainingSection += 'batch_size=batch_size, epochs=epochs, '\n",
    "        trainingSection += 'validation_data=(x_test, y_test), callbacks=[model_checkpoints])'\n",
    "    \n",
    "    return trainingSection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEvaluationSection():\n",
    "    evaluation='score = model.evaluate(x_test, y_test, verbose=0)\\n'\n",
    "    evaluation+='\\nprint(\\'Test loss:\\', score[0])'\n",
    "    evaluation+='\\nprint(\\'Test accuracy:\\', score[1])'\n",
    "    evaluation+='\\nfileEvaluation = open(\\'' + googleBaseFolder +  'EvaluationReport.txt\\', \\'a+\\')'\n",
    "    #evaluation+='\\nfileEvaluation.write(\\'File: ' + outFileName + ' Accuracy : ' + str(score[1])+ 'loss : ' + str(score[0]) + 'Training Time(S) : ' + trainingTime))'\n",
    "    evaluation+='\\nfileEvaluation.write(\\'\\\\nFile: ' + outFileName + '\\\\tAccuracy : \\' + str(score[1]) + \\'\\\\tLoss : \\' + str(score[0]) + \\'\\\\tTraining Time(S) : \\' + trainingTime + \\'\\')'\n",
    "    evaluation+='\\nfileEvaluation.close()'\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFileHeader():\n",
    "    headerSection = \"#*****************************************\"\n",
    "    headerSection += \"\\n#Author : Hencil Peter\"\n",
    "    headerSection += \"\\n#File Name : \" + outFileName\n",
    "    headerSection += \"\\n#Timestamp : \" + str(dt.datetime.now())\n",
    "    headerSection += \"\\n#*****************************************\"\n",
    "    return headerSection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ProcessHyperparameters(token):\n",
    "    global batch_size\n",
    "    global epochs\n",
    "    \n",
    "    collenIndex = token.index(':')\n",
    "    key = token[:collenIndex]\n",
    "    value = token[collenIndex + 1 :]\n",
    "    if (key=='BatchSize'):\n",
    "        batch_size=value\n",
    "    elif(key=='Epochs'):\n",
    "        epochs = value\n",
    "        \n",
    "    #print('batch size =', batch_size, 'epochs =', epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessHeader(token):\n",
    "    global outFileName\n",
    "    collenIndex = token.index(':')\n",
    "    outFileName = token[collenIndex + 1 :] + \".py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessOptimizer(token):\n",
    "    global OptimizerUsed\n",
    "    collenIndex = token.index(':')\n",
    "    key = token[:collenIndex]\n",
    "    value = token[collenIndex + 1 :]\n",
    "    value = value.strip()\n",
    "    print('Key', key)\n",
    "    print('Value', value)\n",
    "    if (value=='SGD'):\n",
    "        OptimizerUsed = 'SGD(lr=0.01)'\n",
    "    elif(value=='RMS'):\n",
    "        OptimizerUsed = 'RMSprop(lr=0.0001, decay=1e-6)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessAugmentation(token):\n",
    "    global Augmentation\n",
    "    collenIndex = token.index(':')\n",
    "    key = token[:collenIndex]\n",
    "    value = token[collenIndex + 1 :]\n",
    "    value = value.strip()\n",
    "    if (value=='True'):\n",
    "        Augmentation = 'True'\n",
    "    else:\n",
    "        Augmentation = 'False'\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNextToken(input):\n",
    "    token = ''\n",
    "    tokenExcludedString = ''\n",
    "    \n",
    "    if (input.find(';')!= -1):\n",
    "        collenIndex = input.index(';')\n",
    "        token = input[:collenIndex]\n",
    "        tokenExcludedString = input[collenIndex + 1:]\n",
    "    elif len(input) > 0 :\n",
    "        token = input\n",
    "        \n",
    "    return token, tokenExcludedString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNextParameter(input):\n",
    "    if (len(input) == 0):\n",
    "        return '',''\n",
    "    \n",
    "    parameter = ''\n",
    "    parameterExcludedString = ''\n",
    "    \n",
    "    if (input.find(',')!= -1):\n",
    "        commaIndex = input.index(',')\n",
    "        parameter = input[:commaIndex]\n",
    "        parameterExcludedString = input[commaIndex + 1:]\n",
    "    elif len(input) > 0 :\n",
    "        parameter = input\n",
    "        \n",
    "    return parameter, parameterExcludedString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetParameter(parametersList, prefix):\n",
    "    parameter = ''\n",
    "    \n",
    "    for index, value in enumerate(parametersList):\n",
    "        if value.startswith(prefix):\n",
    "            parameter = value\n",
    "            \n",
    "    return parameter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddModel(model, token):\n",
    "    collenIndex = token.index(':')\n",
    "    modelName = token[collenIndex + 1:]\n",
    "    #print(modelName)\n",
    "    if (modelName == 'Sequential'):\n",
    "        model = Sequential  \n",
    "    str='model = Sequential()'\n",
    "    global layers\n",
    "    layers += '\\n'+ str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddConvoltionLayer(model, token):\n",
    "    collenIndex = token.index(':')\n",
    "    \n",
    "    parameters = token[collenIndex + 1:]\n",
    "     \n",
    "    filter =''\n",
    "    kernel = ''\n",
    "    padding =''\n",
    "    imageSize =''\n",
    "    parameterList = parameters.split(',')\n",
    "    \n",
    "    #print(parameterList)\n",
    "    if (len(parameterList) > 0):\n",
    "        filter = GetParameter(parameterList, 'Filter')\n",
    "        kernel = GetParameter(parameterList, 'Kernel')\n",
    "        padding = GetParameter(parameterList, 'Padding')\n",
    "        imageSize = GetParameter(parameterList, 'InputSize')\n",
    "        bias = GetParameter(parameterList, 'Bias')\n",
    "        kInit = GetParameter(parameterList, 'KInit')\n",
    "        bInit = GetParameter(parameterList, 'BInit')\n",
    "    \n",
    " \n",
    "    \n",
    "    str = 'model.add(Conv2D('\n",
    "    if (len(filter) > 0): #Add Filter\n",
    "        filter = filter[filter.index('|') + 1:]\n",
    "        str += filter\n",
    "    \n",
    "    if (len(kernel)>0): #Add Kernel\n",
    "        kernel = kernel[kernel.index('|') + 1:]\n",
    "        underscoreIndex = kernel.index('_')\n",
    "        str += ',kernel_size=(' + kernel[ : underscoreIndex] + ',' + kernel[ underscoreIndex + 1:] + ')'\n",
    "        \n",
    "    \n",
    "    if (len(padding) > 0):#Add Padding\n",
    "        padding = padding[padding.index('|') + 1:]\n",
    "        str+= \",padding='\" + padding + \"'\"\n",
    "    \n",
    "    if (len(imageSize) > 0):#Add Input Shape \n",
    "        imageSize = imageSize[imageSize.index('|') + 1:]\n",
    "        parts = imageSize.split('_')\n",
    "        str += ',input_shape=(' +  parts[0] + ',' + parts[1] + ',' + parts[2] +')'\n",
    "        \n",
    "    if (len(bias)>0): # Add Bias\n",
    "        bias = bias[bias.index('|') + 1:]\n",
    "        str += \",use_bias='\" + bias + \"'\"\n",
    "    \n",
    "    if (len(kInit) > 0): #Add Kernel Initializer\n",
    "        kInit = kInit[kInit.index('|') + 1:]\n",
    "        str += \",kernel_initializer='\" + kInit + \"'\"\n",
    "    \n",
    "    if (len(bInit) > 0): # Add Bias Initializer\n",
    "        bInit = bInit[bInit.index('|') + 1:]\n",
    "        str += \",bias_initializer='\" + bInit + \"'\"\n",
    "                    \n",
    "    str+='))'\n",
    "    #print(str)\n",
    "    global layers\n",
    "    layers += '\\n' + str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddActivationLayer(model, token):\n",
    "    \n",
    "    collenIndex = token.index(':')\n",
    "    \n",
    "    activationFunctionName = token[collenIndex + 1:]\n",
    "    \n",
    "    str = \"model.add(Activation(\\'\"  + activationFunctionName.strip() + \"\\'))\"\n",
    "    #print(str)\n",
    "    global layers\n",
    "    layers += '\\n' + str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    " def AddMaxPooling2DLayer(model, token):\n",
    "    collenIndex = token.index(':')\n",
    "    \n",
    "    poolSize = token[collenIndex + 1:]\n",
    "    underscoreIndex =  poolSize.index('_')        \n",
    "    str = \"model.add(MaxPooling2D(pool_size=(\"  + poolSize[ : underscoreIndex] + ',' + poolSize[ underscoreIndex + 1:]  + \")))\"\n",
    "    #print(str)\n",
    "    global layers\n",
    "    layers += '\\n' + str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddDropoutLayer(model, token):\n",
    "    collenIndex = token.index(':')\n",
    "    \n",
    "    dropout = token[collenIndex + 1:]\n",
    "    str = \"model.add(Dropout(\" + dropout  + \"))\"\n",
    "    #print(str)\n",
    "    global layers\n",
    "    layers += '\\n'+ str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddDenseLayer(model, token):\n",
    "    collenIndex = token.index(':')\n",
    "    \n",
    "    dense = token[collenIndex + 1:]\n",
    "    str = \"model.add(Dense(\" + dense  + \"))\"\n",
    "    #print(str)\n",
    "    global layers\n",
    "    layers += '\\n' + str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddFlattenLayer(model, token):\n",
    "    str = \"model.add(Flatten())\"\n",
    "    #print(str)\n",
    "    global layers\n",
    "    layers += '\\n' + str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessToken(model, token):\n",
    "    if (len(token) == 0):\n",
    "        return\n",
    "\n",
    "    #print('Token : ', token)\n",
    "    \n",
    "\n",
    "    \n",
    "    if (token.startswith('Type')): # Type of the model\n",
    "        AddModel(model, token)\n",
    "    elif (token.startswith('Conv2D')):\n",
    "        AddConvoltionLayer(model, token)\n",
    "    elif (token.startswith('Activation')):\n",
    "        AddActivationLayer(model, token)\n",
    "    elif (token.startswith('MaxPooling2D')):\n",
    "        AddMaxPooling2DLayer(model, token)\n",
    "    elif (token.startswith('Dropout')):\n",
    "        AddDropoutLayer(model, token)\n",
    "    elif (token.startswith('Dense')):\n",
    "        AddDenseLayer(model, token)\n",
    "    elif (token.startswith('Flatten')):\n",
    "        AddFlattenLayer(model, token)\n",
    "    elif(token.startswith('BatchSize') | token.startswith('Epochs')):\n",
    "        ProcessHyperparameters(token)\n",
    "    elif(token.startswith('Opt')):\n",
    "        ProcessOptimizer(token)\n",
    "    elif(token.startswith('Augmentation')):\n",
    "        ProcessAugmentation(token)\n",
    "    elif(token.startswith('Id')):\n",
    "        ProcessHeader(token)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and Save python file\n",
    "\n",
    "def CreateAndSaveModelFile():\n",
    "    print(formattedOutFolder)\n",
    "    if not os.path.exists(formattedOutFolder):\n",
    "        os.makedirs(formattedOutFolder)\n",
    "    \n",
    "    modelOutputFile = open(formattedOutFolder + outFileName,'w')\n",
    "    modelOutputFile.write(GetFileHeader())\n",
    "    modelOutputFile.write('\\n\\n')\n",
    "    modelOutputFile.write(GetImportSection())\n",
    "    modelOutputFile.write('\\n\\n#Hyper parameters')\n",
    "    modelOutputFile.write('\\nbatch_size=' + batch_size)\n",
    "    modelOutputFile.write('\\nepochs=' + epochs)\n",
    "    modelOutputFile.write('\\nnum_classes =' + num_classes )\n",
    "    modelOutputFile.write('\\ntrainingTime=\\'\\'');\n",
    "\n",
    "    modelOutputFile.write('\\n\\n#Preprocess the data')\n",
    "    modelOutputFile.write(GetDataLoadAndPreprocessingSection())\n",
    "    modelOutputFile.write('\\n\\n#Construct network Layers')\n",
    "    modelOutputFile.write(layers)\n",
    "    modelOutputFile.write('\\n\\n#Train the model\\n')\n",
    "    modelOutputFile.write('\\nt1 = dt.now()\\n')\n",
    "    modelOutputFile.write(GetTrainingSection())\n",
    "    modelOutputFile.write('\\nt2 = dt.now()')\n",
    "    modelOutputFile.write('\\ndelta = t2 - t1')\n",
    "    modelOutputFile.write('\\ntrainingTime = str(delta.total_seconds())')\n",
    "    modelOutputFile.write('\\n\\n#Evaluate the accuracy\\n')\n",
    "    #modelOutputFile.write('print(\\'Score = \\',model_log[0],\\'Loss = \\', model_log[1])' )\n",
    "    modelOutputFile.write(GetEvaluationSection())\n",
    "    modelOutputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n",
      "Key Opt\n",
      "Value RMS\n",
      "optimizer RMSprop(lr=0.0001, decay=1e-6)\n",
      ".\\SampleOut_2018-12-03_23-22-30.624946\\\n",
      "Completed the current network layer construction..\n"
     ]
    }
   ],
   "source": [
    "modelInput = open(modelInputFileName,'r')\n",
    "modelInputList = modelInput.readlines()\n",
    "modelCount = 0\n",
    "model = Sequential\n",
    "global outFolder\n",
    "#global OptimizerUsed\n",
    "for input in modelInputList:\n",
    "    modelCount+=1\n",
    "    layers = ''\n",
    "    #print('Started Constructing Model : ', modelCount, input)\n",
    "    tokenExcludedString = input\n",
    "    #print('Token : ', tokenExcludedString)\n",
    "    while (len(tokenExcludedString) > 0 ):\n",
    "        token, tokenExcludedString = GetNextToken(tokenExcludedString)\n",
    "        ProcessToken(model, token)\n",
    "        #print('token : ', token)\n",
    "        \n",
    " \n",
    "    #print('optimizer',OptimizerUsed)\n",
    "    CreateAndSaveModelFile()\n",
    "    print('Completed the current network layer construction..')\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models are Generated!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "print('Models are Generated!!!!!!!!!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
